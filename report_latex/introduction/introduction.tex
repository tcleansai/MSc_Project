\chapter{Introduction}
\pagenumbering{arabic}
\section{Motivation}
Automatic Speech Recognition is a very important and popular technology in Human Computer Interactions. In recent years, device and software that support ASR system are increasing rapidly. Diversification of interacting with a system is increasing. People are not satisfied with just interacting with a computer through mouth and keyboards. Automatic Speech Recognition is a very good technology for HCI as human-human communication are mostly through speech. Audiovisual automatic speech recognition has shown significant improvement by including visual information. In human-human communication, people are able to understand others by reading the signal of facial expression, some non-linguistic vocalization, gestures. \cite{petridis2011prediction} Laughter are commonly used in human social conversation. However, the research in recognising the non-linguistic vocalization is rare. Moreover, people usually not just talking during conversation, they could also be smiling or eating while interaction with other people. This project intend to try to automatically distinguish video sequence of some different facial expressions, such as normal face, eating and talking.
\section{Thesis}
This project try to detect eating, talking and normal state of face from videos that are recorded using webcam. The process of project contains two main steps, first step is to extract suitable features that could accurately represent facial expression of each frame. Second step is to experiment use extracted feature to train classifier that could correctly classifier a video sequence.
\section{Contribution}
In this project, we integrate a sequence of process to extract video features with existing algorithms. The procedure contains tracking facial feature point using Intraface, warping, remove-head pose using deformable model, extract features using local binary pattern.
In this project, we experiment using train a Support Vector Machine classifier with different features. We tried appearance feature, shape feature and combination of both. For appearance feature, we tried to extract 1-block uniform pattern feature and 3-block uniform pattern feature. We also explore the influence of normalize each feature vector by each video. By normalize, I mean substract its mean and divide by its standard deviation.
\section{Outline of Report}
\paragraph{Chapter 2:} Present a brief introduction in Automatic Speech Recognition(ASR) and Audio-visual ASR, visual front end including some definition in this field, basic facial expressions, some application of application in audio-visual biometric.
\paragraph{Chapter 3:} Present the main procedure of extracting appearance feature and shape feature. Compare two different tracker of tracking facial feature points. Describe the methodologies used in the procedure.
\paragraph{Chapter 4:} Present the results of classifier and analysis from different aspects.
\paragraph{Chapter 5:} Evaluate the process of extracting facial features and experiments and describe the limitation and future work of this project.