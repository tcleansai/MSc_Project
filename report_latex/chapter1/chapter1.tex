\chapter{Processing and Methodologies}
In this chapter, I will introduce the procedure of extracting facial features and the tools and methodologies I use.
\section{Processing Flow}
\paragraph{Processing Chart}
\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{imgs/ProcedureChart.png}
\caption{Main Procedure}
\label{fig:proc}
\end{figure}
Figure \ref{fig:proc} shows main procedure of the whole project. At beginning, I tried several trackers. Intraface and DRMF are two trackers I tried and compared most. Two trackers are using different methods and also implemented in different languages. Intraface are programmed in c and matlab and has great interface for matlab. I tried two version of DRMF, DRMF programmed using CUDA which uses parallel processing is quite fast. As the programme of DRMF doesn't integrate extract frames from videos. The images are extracted using external function, then tracked using DRMF. I choose Intraface as the final choose, the reason and comparison will be given in later section. Remove head-pose seems to be a very important part for this project, as subject's head moves frequently in many videos. After having tracking points without head-pose, each face in each frame is warped and scaled to same size grey image. Extracting features is to extract appearance feature of each face in the image. Post-processing is preprocessing before using the data for classification.
\paragraph{Data flow Chart}
\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{imgs/DataFlowChart.png}
\caption{Data Flow}
\label{fig:DF}
\end{figure}
Figure \ref{fig:DF} show data I need for processing. There are two types of encoded video, one is in format of fly and the other is avi. Extracting frames from videos is proceed with Intraface and stored in formats of jpeg and mat which used for processing of matlab. There are several situations that a track is unable to track a face in the image such as no subject in the image, the head is face to a very large angle from frontal face, face is partially not show in the frame. Frame index points to those images which the tracker is able to tracker a face in a frame. Image is the frame images stored in mat format. Different tracker may tracks different number of characteristic facial points. Intraface tracks 49 facial points and DRMF tracks 66 points. Deformed points is the tracking point after removed head-pose. Warped Images is the face after remove head-pose and background which only leaves the meshes build by tracking points. Appearance feature is face feature extracted using local binary pattern (LBP). As the image size from image to warped images are changed, the points is rescaled from deformed point to scaled points.

\section{Face Alignment}

Face alignment is to align face in one image with respect to the same face in another image. Face alignment techniques are used to track characteristic facial points in image sequences. In this project, the aim of face alignment is to localise the feature points on face images. The points are usually around eyes, nose, mouth, and outline. Face alignment techniques are essential on face recognition, modelling and synthesis. There are three main different approaches Parametrized Appearance Models(PAMs), Discriminative approaches, Part-based deformable models. Parametrized appearance models contains many models such as active appearance models (AAMs), morphrable models, eigentrackings, and template tracking \cite{xiong2013supervised}. All these models are using Principle Component Analysis(PCA) method to parametrize a face. A face could approximately decomposed as linear combination of shape basis and appearance basis. The problem of face alignment could be refer as minimising the difference between the constructed PAM and the face. Common approach is use Gauss-Newton methods \cite{xiong2013supervised}. Discriminative approaches are to learn the linear regression between the head move and appearance change. Part-based deformable model perform face alignment by maximising the posterior likelihood of part locations given image\cite{xiong2013supervised}.

\subsection{Active Appearance Model}
Active Appearance Model (AAMs) is defined as a generative model of a certain visual phenomenon in \cite{matthews2004active}. AAMs are conceptually related to morphable models, constrained models and active blobs. In this project, it is refer to a model of face. As AAM is conceptually related to other parameterized appearance model, so it is introduced as an example of parameterized appearance model for understanding purpose. According to \cite{matthews2004active}, there are two types of AAMs, one refers as independent shape and appearance models, which model shape and appearance independently, and the other refers as combined shape and appearance models, which parameterized shape and appearance model with a single set of linear parameters \cite{matthews2004active}. Normally AAMs appears along with a fitting algorithm. However, in the following context, it only refers to a model.\cite{matthews2004active} gave a well explain about what is an AAM, most of following theory are from \cite{matthews2004active}.
\paragraph{Shape}
Shape of a face $s$ is defined by coordinates $(x,y)$ of $v$ vertices of face points and the mesh they built:
\begin{equation}
s = (x_{1},y_{1},x_{2},y_{2},...,x_{v},y_{v})^{T}
\end{equation}
\newline
$s$ also can be expressed as a base shape $s_{0}$ plus linear combination of $n$ shape vectors $s_{i}$:
\begin{equation}
s = s_{i} + \sum_{i =1}^{n}p_{i}s_{i}
\end{equation}
\paragraph{Appearance}
For all pixels x in the mesh $s_{0}$, appearance $A(0)$ can be expressed by base appearance $A_{0}(x)$ and m appearance images $A_{i}(x)$.
\begin{equation}
A(x) = A_{0}(x) + \sum_{i=1}^{m}\lambda_{i}A_{i}(x) \qquad \forall x \in s_{0}
\end{equation}
\newline
AAMs are usually computed by applying Principle Component Analysis (PCA) to choose images. The chosen images contains a variety of shapes. The base shape $s_{0}$ is the mean shape and the vector $s_{v}$ is the eigenvector corresponding to the largest $v$ eigenvalues. The base appearance $A_{0}$ and the appearance $A_{i}$ is computed by applying Principle Component Analysis to a set of shape normalised images.
\paragraph{Model} 
$W(x:p)$ is the warp from $s_{0}$ to $s$. Then the model $M$ set the appearance of $W(x:p)$ to $A(x)$.
\begin{equation}
M(W(x:p)) = A(x)
\end{equation}
\newline
Combined AAMs
\newline
Combined AAMs just use parameter $c = (c_{1},c_{2},...)^{T}$ to parametrize shape:
\begin{equation}
s = s_{0} + \sum_{i=1}^{l}c_{i}s_{i}
\end{equation}
and appearance:
\begin{equation}
A(x) = A_{0}(x) + \sum_{i=1}^{l}c_{i}A_{i}(x)
\end{equation}
\begin{figure}[ht]
\centering
\includegraphics[width = \textwidth]{imgs/AAM_Model.png}
\caption{An AAM instantiation from \cite{matthews2004active}}
\label{fig:AAMI}
\end{figure}
An example of AAM instantiation is clearly shown in figure \ref{fig:AAMI}.
\subsection{Trackers}
There are many different trackers for tracking facial feature points. Different tracker may using different approaches, so they are suitable for different situations. I tried two main trackers for tracking characteristic facial points, one is Intraface \cite{xiong2013supervised} which use suppervised decent method, the other is DRMF \cite{asthana2013robust} which use discriminative response map fitting. According to my using experiment, Intraface is very good at tracking motion face and DRMF is very good at fitting face model to a more standard face even with low resolutions. The number of facial points they track are also differnt.
\subsubsection{Intraface}
\cite{xiong2013supervised} implies image alignment  can be posed as solving a nonlinear optimization problem. It uses Supervised Descent Method for minimising Non-linear Least Square(NLS) function, which avoids calculating the Hessian and the Jacobian that could be computationally expensive. For this reason, the running time of Intraface shows that the method is very effective and efficient.
\paragraph{Tracking Points}
Figure \ref{fig:IPI} shows the tracking points of Intraface. This tracker tracks 49 facial feature points. As you can see the eyes, nose, mouth, unfortunately the jaw and cheek may contain visual information that may help classification.
\begin{figure}[ht]
\centering
\includegraphics[width = 80mm]{imgs/FacialIndexIntraface.png}
\caption{Intraface landmark points}
\label{fig:IPI}
\end{figure}
\paragraph{Eating and Talking Sequence}
Figure \ref{fig:IES} shows a sequence of image of eating tracked by Intraface. The point are aligned very precisely along the face. Figure \ref{fig:ITS} shows a talking sequences of image tracked by Intraface. The landmark points of mouth is very accurate.
\newpage
\begin{figure}[p]
\centering
\includegraphics[width=110mm]{imgs/Tracking_Intraface_eating_red.png}
\caption{Eating sequence tracked by Intraface}
\label{fig:IES}
\includegraphics[width=110mm]{imgs/Talking_Intraface_140711_176_184.png}
\caption{Talking sequence tracked by Intraface}
\label{fig:ITS}
\end{figure}
\newpage
\subsubsection{DRMF}
DRMF uses novel discriminative regression based on Constrained Local Models(CLMs) for face alignment\cite{asthana2013robust}. The basic idea of DRMF is to fit a face for each frame of a video. After locating the position of a face, the tracker tries to fit a trained constrained local model to fit the face. Sometimes the fitting result is not very good and the landmark points of mouth region is not very accurate.
\paragraph{Tracking Points}
Figure \ref{fig:DPI} shows 66 facial feature points tracked by DRMF, the extra 17 points are the point around face bound. Other landmark points are at the same order as Intraface.
\begin{figure}[ht]
\centering
\includegraphics[width = 80mm]{imgs/FacialIndexDRMF.png}
\caption{DRMF landmark points}
\label{fig:DPI}
\end{figure}
\paragraph{Talking and Talking Sequence}
Figure \ref{fig:DES} and \ref{fig:DTS} show image sequences of eating and talking tracked by DRMF. It is easy to see that the facial feature points are not aligned as better as Intraface. However, the advantage of DRMF is that with the extract bound points of face, we are able to extract the visual information about the jaw and cheek, which may be helpful for classification.
\newpage
\begin{figure}[p]
\centering
\includegraphics[width=100mm]{imgs/Tracking_DRMF_eating.png}
\caption{Eating sequence tracked by DRMF}
\label{fig:DES}
\includegraphics[width=100mm]{imgs/Talking_DRMF_140711_176_184.png}
\caption{Talking sequence tracked by DRMF}
\label{fig:DTS}
\end{figure}
\newpage
\subsection{Comparison}
The following are some examples for comparing two trackers. Intraface is generally better than DRMF in accuracy and efficient. There are two version of DRMF tracker one is implemented by CUDA language the other is by C language. Although the C version of DRMF is very slow and very easy to run out of memory, the version implementd by CUDA is very fast as CUDA is using parallel computing. However, for cace points alignment, DRMF is not as accurate as Intraface. In some situations, DRMF try to fit a face and the fitting result is awful. The images with red points are tracked by Intraface, and the images with blue points is tracked by DRMF.
\newline
In figure \ref{fig:cmp01}, compare top left and top right images, we can see Intraface does not tracke the face of the smaller face, DRMF tracked the smaller face instead of the large face. This shows the advantage of DRMF on track face of low resolution face. I tried to use Intraface to track a image with multiple face, Intraface is able to track multiply faces in one image. So this means, Intraface is not good at tracking face on low resolution face. Compare the lower two images on the right hand side, the feature points of nose is not proper aligned, this is caused by imperfect of the fitting algorithm. The feature points of face bound are also not well aligned. Comparing the alignment of eye alignment on the left hand side of both traker, Intraface is better than DRMF. The feature points of right eye brows of the mid right image are also not algined precisely.
\newline
In figure \ref{fig:cmp02}, in the top left image, DRMF is unable to fit a face to the face as the face is facing to the left. Of course, Intraface is unable to apply face alignment to a image doesn't show half of the face like this, it choose to ignore this image. In lower two images on the left hand side shows two situations that DRMF fail to fitting face model to face because of the face is partial out of the image frame. The middle one shows that the fitting face points are force to stay in the frame and the mouth are moved up to close nose. The lower one image shows that as most of mouth region is out of frame, the model is fitted to the left eye forcefully. The middle and lower images on the right hand side shows that Intraface would ignore those points that are out of frame. It seems using Supervised Descent Method is very good at tracking face that moves. However, there is a bug of this traker, while tracking the video, if the subject moves hand to cover the mouth, the points of mouth would be pushed upwords, and it will not come back even the hand is moved away, unless, the traker loss the face and retrack the face.
\begin{figure}
\centering
\includegraphics[width=110mm]{imgs/Tracking_Intraface_DRMF_compare_00.png}
\caption{Tracking result: images with red points on the left hand side are tracked by Intraface and images with blue points on the right hand side are tracked by DRMF}
\label{fig:cmp01}
\includegraphics[width=110mm]{imgs/Tracking_Intraface_DRMF_comparison.png}
\caption{Tracking result, images with red points on the right hand side are tracked by Intraface and images with blue points on the left hand side are tracked by DRMF}
\label{fig:cmp02}
\end{figure}
\newpage
\section{Remove Head-pose}
Subjects were unrestricted while they were recording the video, their head pose are vary different. The coordinate of facial feature points are different for each video frame. In order to unite the head, we need to remove the head pose from the coordinates of facial feature points.  If define the honrizontal direction is x, the vertical direction is y and z is the direction, subject facing camera. It is very easy to remove head-pose in x-y direction, just by rotating and scaling the points would remove the head-pose. If the subject had a head-pose in x-z and y-z direction, it would be hard to find the correct transformation matrix for tracked facial points. The algroithm of removing head-pose from tracking points is \cite{saragih2011deformable}. Basically, it has a deformable 3-D Constrained Local Model(CLM), minimize the error of fitting the model and the 2D points and then remove head-pose and give the new 2D points. Figure \ref{fig:RHP01} and \ref{fig:RHP02} gave two example of orginal track points and deformed points. From figure \ref{fig:RHP01} and \ref{fig:RHP02} we can see this method could remove head-pose without losing information of mouth shape.
\begin{figure}[ht]
\centering
\includegraphics[width=150mm]{imgs/160954_Deform_213.png}
\caption{Traking points and Deformed Points, Example 1}
\label{fig:RHP01}
\includegraphics[width=150mm]{imgs/160954_Deform_233.png}
\caption{Traking points and Deformed Points, Example 2}
\label{fig:RHP02}
\end{figure}
\newpage
\section{Warping}
There are two types of features we need to extract, shape feature and appeanrance feature, the previous section just remove heap-pose of shape feature vector. The appearance of face on image is not correctly showing a face that could be directly used for classification, as the face is not facing to frontal. In order to have head-pose free face, we need to distort the image to the one we need. In here I use Piece-wise Affine to warp the image. According to the model in Active Appearance Model. We need to warping image from one to another with respect to the mapping of shape feature points set ${X_{1},X_{2},...X_{n}}$ into another point set ${x'_{1},X'_{2},...X'_{n}}$. Each point is represented as $X = [x,y]^{T}$. The mapping function would be:
\begin{equation}
f(X_{i}) = X'_{i} \quad \forall \ i = 1...n
\label{eq:W1}
\end{equation}
\newline
Piece-wise Affine assume that f is locally linear. In 2-D framework like 2-D AAM, first find the mesh-grid constructed by all shape feature points. Delaunay triangulation is a good way to express it. In Delaunay triangulation, there is no points inside its circumcircle. Then the problem is to find the mapping function $f$ to map the trianglear mesh of the first point set and the second point set. For each points on each triangle of the first point set $I$ can be mapped to unique points on each triangles of the second point set $I'$ by affine transformation, which is combination of translation, rotation and scaling. Assume $X_{1}$, $X_{2}$ and $X_{3}$ are a vertices of a triangle in $I$, then the points inside the triangle can be writen as:
\begin{align*}
x 
& = X_{1} + \beta (X_{2}-X_{1})+\gamma (X_{3}-X_{1}) \\
&  = \alpha X_{1} + \beta X_{2} + \gamma X_{3}
\end{align*}
\begin{figure}[ht]
\centering
\includegraphics[width=90mm]{imgs/Warping_Intraface_213.png}
\caption{Talking sequence tracked by DRMF}
\end{figure}
\newpage
\section{Feature Extraction}
The image after warping is not directly used for classfication, image feature are stelected to represent the image. Points, edges, ojects and texture are important features of an image. In this project, Local Binary Pattern are used for calssification as it's a very powerful feature for texuture classfication. 
\subsection{Local Binary Pattern}
LBP is chosen to be the feature for representing region of interest. \cite{shan2009facial} obtained best recognition result by using Support Vector Machine with Boosted-LBP features. Moreover, \cite{shan2009facial} shows LBP features perform stably and robustly on low-resolution face images. In the beginning, LBP was used for texture analysis, it has natural advantage on computational simplicity and ignoring illumination changes.
\newpage
\section{Postprocessing}
As it is known large margin classifiers are sensitive to the way features are scaled, it's better to normalize either the data or the kernal function \cite{ben2010user}. Feature of a image is represented by a vector, the number in the vector would influence the weight of feature in this dimension. As I would like to treat each dimension similar, I scale the number in the range of $[0,1]$.
\paragraph{Normalization}
The perfromance of SVM is usually better if the data is normalized. There are two ways of applying normalization, standardlizing the input features or normalizing the kernal function. As I am using the builtin function of libsvm \cite{CC01a}, so I standardlising the input features by substracting its mean and divide by its standard deviation.
\paragraph{Scaling}
The range of appearance feature vector and shape feature vector is different. I would like to treat then as the same. So I scale all the vector into the range of $[0, 1]$, by substract the minmun and divide by the maximum number of each dimension.